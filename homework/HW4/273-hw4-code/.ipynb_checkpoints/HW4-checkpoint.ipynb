{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><font size = 5><b><i>Assignment4</i></b></font></center>\n",
    "<div style=\"text-align: right\"><i>By Yi Zhou</i></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Decision Trees for Spam Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy H(y) of this binary class variable y: 0.970950594455\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def binary_entropy(p):\n",
    "    if p == 0.0 or p == 1.0:\n",
    "        return 0\n",
    "    \n",
    "    return (-p) * math.log(p,2.0) - (1.0 - p) * math.log(1.0 - p, 2.0)\n",
    "hy = binary_entropy(0.6)\n",
    "print \"Entropy H(y) of this binary class variable y: \" + str(hy) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information gain for feature x1 is: 0.046439344671\n",
      "Information gain for feature x2 is: 0.609986547011\n",
      "Information gain for feature x3 is: 0.00580214901435\n",
      "Information gain for feature x4 is: 0.0912774462417\n",
      "Information gain for feature x5 is: 0.00580214901435\n",
      "We should choose feature 2 as root\n"
     ]
    }
   ],
   "source": [
    "def binary_information_gain(hy,x_true,x_true_y_true,x_false_y_true):\n",
    "    return hy - x_true * binary_entropy(x_true_y_true) - (1 - x_true) * binary_entropy(x_false_y_true)\n",
    "print \"Information gain for feature x1 is: \" + str(binary_information_gain(hy,0.6,0.5,0.25))\n",
    "print \"Information gain for feature x2 is: \" + str(binary_information_gain(hy,0.5,0.0,0.8))\n",
    "print \"Information gain for feature x3 is: \" + str(binary_information_gain(hy,0.7,3.0 / 7.0,1.0 / 3.0))\n",
    "print \"Information gain for feature x4 is: \" + str(binary_information_gain(hy,0.7,2.0 / 7.0,2.0 / 3.0))\n",
    "print \"Information gain for feature x5 is: \" + str(binary_information_gain(hy,0.3,1.0 / 3.0,3.0 / 7.0))\n",
    "print \"We should choose feature 2 as root\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "-1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "-1\n",
      "As we can see my decision tree split all data perfectly\n"
     ]
    }
   ],
   "source": [
    "def decision_tree(x1,x2,x3,x4,x5):\n",
    "    y = None\n",
    "    if x2 == 1:\n",
    "        y = -1\n",
    "    else:\n",
    "        if x4 == 0:\n",
    "            y = 1\n",
    "        else:\n",
    "            if x1 == 1:\n",
    "                y = 1\n",
    "            else:\n",
    "                if x3 == 1:\n",
    "                    y = -1\n",
    "                else:\n",
    "                    y = 1\n",
    "    return y\n",
    "print(decision_tree(0,0,1,1,0))\n",
    "print(decision_tree(1,1,0,1,0))\n",
    "print(decision_tree(0,1,1,1,1))\n",
    "print(decision_tree(1,1,1,1,0))\n",
    "print(decision_tree(0,1,0,0,0))\n",
    "print(decision_tree(1,0,1,1,1))\n",
    "print(decision_tree(0,0,1,0,0))\n",
    "print(decision_tree(1,0,0,0,0))\n",
    "print(decision_tree(1,0,1,1,0))\n",
    "print(decision_tree(1,1,1,1,1))\n",
    "print \"As we can see my decision tree splits all data perfectly\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Decision Trees in Python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mltools as ml\n",
    "X = np.genfromtxt('data/X_train.txt', delimiter=None)\n",
    "Y = np.genfromtxt('data/Y_train.txt', delimiter=None) \n",
    "X,Y = ml.shuffleData(X,Y)\n",
    "# and simlarly for test data features and target values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 14)\n"
     ]
    }
   ],
   "source": [
    "print X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
